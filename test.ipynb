{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, './YOLOv5-Lite')\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import check_img_size, non_max_suppression, scale_coords\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "class YOLOv5LiteDetector:\n",
    "    def __init__(self, \n",
    "                 weights='weights/best.pt', \n",
    "                 img_size=640, \n",
    "                 conf_thres=0.45, \n",
    "                 iou_thres=0.5,\n",
    "                 device='',\n",
    "                 view_img=False):\n",
    "        \n",
    "        self.device = select_device(device)\n",
    "        self.model = attempt_load(weights, map_location=self.device)\n",
    "        self.model.eval()\n",
    "        self.img_size = check_img_size(img_size, s=int(self.model.stride.max()))\n",
    "        self.conf_thres = conf_thres\n",
    "        self.iou_thres = iou_thres\n",
    "        self.half = self.device.type != 'cpu'\n",
    "        if self.half:\n",
    "            self.model.half()\n",
    "        self.names = self.model.module.names if hasattr(self.model, 'module') else self.model.names\n",
    "        self.view_img = view_img\n",
    "\n",
    "    def detect(self, img0):\n",
    "        \"\"\"\n",
    "        单张图像推理接口\n",
    "        img0: numpy array (BGR) 原始图像\n",
    "\n",
    "        返回: (detections, result_img)\n",
    "            detections: list of dict, 每个dict包含bbox, conf, class_id, label\n",
    "            result_img: numpy array, 已画框的图像\n",
    "        \"\"\"\n",
    "        # Resize and pad image to model input size\n",
    "        from utils.datasets import letterbox\n",
    "        img = letterbox(img0, new_shape=self.img_size)[0]\n",
    "\n",
    "        # Convert BGR to RGB, transpose to channel first, and convert to torch tensor\n",
    "        img = img[:, :, ::-1].copy().transpose(2, 0, 1)\n",
    "        img = torch.from_numpy(img).to(self.device)\n",
    "        img = img.half() if self.half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0-255 to 0.0-1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # 推理\n",
    "        pred = self.model(img, augment=False)[0]\n",
    "        pred = non_max_suppression(pred, self.conf_thres, self.iou_thres)[0]\n",
    "\n",
    "        detections = []\n",
    "        im0 = img0.copy()\n",
    "\n",
    "        if pred is not None and len(pred):\n",
    "            # 根据 letterbox 缩放恢复原图坐标\n",
    "            pred[:, :4] = scale_coords(img.shape[2:], pred[:, :4], im0.shape).round()\n",
    "            for *xyxy, conf, cls in reversed(pred):\n",
    "                label = f'{self.names[int(cls)]} {conf:.2f}'\n",
    "                plot_one_box(xyxy, im0, label=label, color=(0, 255, 0), line_thickness=2)\n",
    "                detections.append({\n",
    "                    'bbox': [int(x.item()) for x in xyxy],  # [x1, y1, x2, y2]\n",
    "                    'conf': conf.item(),\n",
    "                    'class_id': int(cls),\n",
    "                    'label': self.names[int(cls)]\n",
    "                })\n",
    "\n",
    "        if self.view_img:\n",
    "            cv2.imshow('YOLOv5Lite Detection', im0)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "        return detections, im0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c853c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m      5\u001b[0m detector \u001b[38;5;241m=\u001b[39m YOLOv5LiteDetector(\n\u001b[0;32m      6\u001b[0m     weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLOv5-Lite/yolo_lite_cuadc8/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# 本地模型\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     view_img\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 图像路径可以是单个图像或目录\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m detection, img \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 支持文件夹或图像路径\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m, in \u001b[0;36mYOLOv5LiteDetector.detect\u001b[1;34m(self, img0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Convert BGR to RGB, transpose to channel first, and convert to torch tensor\u001b[39;00m\n\u001b[0;32m     47\u001b[0m img \u001b[38;5;241m=\u001b[39m img[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     49\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mhalf() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;28;01melse\u001b[39;00m img\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# uint8 to fp16/32\u001b[39;00m\n\u001b[0;32m     50\u001b[0m img \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# 0-255 to 0.0-1.0\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) "
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg') \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "detector = YOLOv5LiteDetector(\n",
    "    weights='YOLOv5-Lite/yolo_lite_cuadc8/weights/best.pt',  # 本地模型\n",
    "    img_size=640,\n",
    "    conf_thres=0.4,\n",
    "    iou_thres=0.5,\n",
    "    device='',  # 使用CUDA默认设备，如无CUDA则用CPU\n",
    "    view_img=True\n",
    ")\n",
    "\n",
    "# 图像路径可以是单个图像或目录\n",
    "detection, img = detector.detect(cv2.imread('1.png'))  # 支持文件夹或图像路径\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"YOLOv5-Lite Detection\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(detection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
